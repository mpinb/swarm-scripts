#!/usr/bin/perl

# ===========================================================================
#
#                            PUBLIC DOMAIN NOTICE
#                     Center for Information Technology (CIT)
#                        National Institute of Health (NIH)
#
#  This software/database is a "United States Government Work" under the
#  terms of the United States Copyright Act.  It was written as part of
#  the author's official duties as a United States Government employee and
#  thus cannot be copyrighted.  This software is freely available
#  to the public for use.  The Center for Information Technology, The
#  National Institutes of Health, and the U.S. Government have not placed
#  any restriction on its use or reproduction.
#
#  Although all reasonable efforts have been taken to ensure the accuracy
#  and reliability of the software and data, CIT, NIH and the U.S.
#  Government do not and cannot warrant the performance or results that
#  may be obtained by using this software or data. CIT, NIH and the U.S.
#  Government disclaim all warranties, express or implied, including
#  warranties of performance, merchantability or fitness for any particular
#  purpose.
#
#  Please cite the author and the "NIH Biowulf Cluster" in any work or product
#  based on this material.
#
# ===========================================================================

# This script is an adaptation of the swarm script for use with SLURM.
use Getopt::Long qw(:config no_ignore_case);
Getopt::Long::Configure("bundling"); # allows option bundling
use POSIX qw(strftime floor ceil);
use File::Temp qw/tempfile tempdir/;
use File::Basename qw/basename/;
use File::Spec;
require File::Spec::Unix;
use File::Path qw(make_path);
#use lib "/usr/local/slurm/lib/perl5/site_perl/5.18.2/x86_64-linux-thread-multi-ld";
#use Slurm;
#use Data::Dumper;
use FileHandle;
use strict;

#use Sys::Hostname;
#dieWithError("Don't run on helix!  Run on the biowulf cluster!") if (hostname() =~ /helix/);

$SIG{HUP}  = \&catch_sig;
$SIG{INT}  = \&catch_sig;
$SIG{KILL} = \&catch_sig;
$SIG{TERM} = \&catch_sig;
$SIG{STOP} = \&catch_sig;

my $PAR;
my $SWARM;
setDefaults();

my %OPT;
my %SLURMOPT;
my $SBATCHOPT;
getCommandLineOptions();
validatePartition();
parseCommands();
distributeCommands();
adjustTime();
report();
#writeCommandFiles() unless $OPT{'no-scripts'};
writeCommandFile() unless $OPT{'no-scripts'};
writeBatchScript() unless $OPT{'no-scripts'};
sleep(2) unless $OPT{debug}; # sleep 2 seconds to prevent weirdness
submitSlurm();
createSymlink() unless $OPT{'no-scripts'};
writeLog() unless $OPT{'no-log'};
writesLog() unless $OPT{'no-log'};
#call_newwall();

sub convertWallTime
{
  my @blah = $_[0] =~ /^(\d+)?-?(\d+):(\d+):(\d+)/;
  if ($#blah == 3) {
    $blah[0]*24*60 + $blah[1]*60 + $blah[2];
  } elsif ($#blah == 2) {
    $blah[0]*60 + $blah[1];
  } else {
    4294967294;
  }
}

#===============================================================================
sub setDefaults
{
  $PAR->{b} = 1; # bundle value of 1
  $PAR->{user} = (getpwuid($>))[0]; # who is this?
  chomp($PAR->{host} = `/bin/hostname`); # where am I?
  $PAR->{pwd} = $ENV{'PWD'}; # what directory is this?
  $PAR->{home} = $ENV{'HOME'}; # user home directory

# Create the basedir where the batch script and command scripts will be written
  #$PAR->{basedir} = sprintf "%s/swarm", $PAR->{home};
  $PAR->{basedir} = $ENV{'SWARMDIR'};
  isDirCreateable($PAR->{basedir}) || dieWithError("can't write to $PAR->{basedir}");
  if (!-d $PAR->{basedir}) {
    mkdir $PAR->{basedir} || dieWithError("Can't create swarm script basedir!");
    chmod 02750,$PAR->{basedir};
  }

# Other defaults
  $PAR->{shell} = "/bin/bash";
  $PAR->{date} = strftime("%b %d %Y %T", (localtime)[0 .. 5]);
  my @tmp = split / /,$PAR->{date};
  $PAR->{time} = $tmp[-1];
  $PAR->{commentChar} = '#';

# The logfile which will be updated
  #$PAR->{logfile} = sprintf "%s/swarm/logs/swarm.log", $PAR->{home};
  $PAR->{logfile} = sprintf "%s/logs/swarm.log", $PAR->{basedir};

# The sbatch logfile which will be updated
  #$PAR->{slogfile} = sprintf "%s/swarm/logs/sbatch.log", $PAR->{home};
  $PAR->{slogfile} = sprintf "%s/logs/sbatch.log", $PAR->{basedir};

# Keep index of tempdirs
  #$PAR->{tempdir_index} = sprintf '%s/swarm/logs/swarm_tempdir.idx', $PAR->{home};
  $PAR->{tempdir_index} = sprintf '%s/logs/swarm_tempdir.idx', $PAR->{basedir};

# * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
# There is no need to keep track of MaxSubmit because swarm will now submit jobarrays.  Each swarm
# is a single job, so it either submits, or doesn't submit.  The value of interest is MaxArraySize,
# which limits the number of subjobs per swarm, er, job.
# * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
  #$PAR->{maxarraysize} = 1000;
  $PAR->{maxarraysize} = 100000;

# * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
# Currently we have nodes with up to 3000 GB of RAM memory
# * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
  #$PAR->{maxmemsize} = 3000;
  $PAR->{maxmemsize} = 64000; # effectively disable this max mem check

# * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
# In addition, we will not be concerned with QOS, as this will be handled downstream by slurm itself.
# * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *

# Make sure sbatch is accessible
  my $sbatch_check = `which sbatch 2>/dev/null`;
  dieWithError("Can't find sbatch.  Is slurm in your path?") unless $sbatch_check;

# Get configuration for partitions
  # my $slurm = Slurm::new();
  # my $x = $slurm->load_partitions();
  # foreach my $i (@{$x->{partition_array}}) {
  #   $PAR->{slurm_partitions}{$i->{name}}{default_time} = $i->{default_time};
  #   $PAR->{slurm_partitions}{$i->{name}}{max_time} = $i->{max_time};
  # }
# Removed the Slurm module dependency by copying code out of batchlim
  my %default_wall;
  my %max_wall;
  open (IN, "/usr/bin/scontrol -o show part | ");
  while (<IN>) {
  my $name;
    (/PartitionName=(\S*)/) && ($name = $1);
    (/DefaultTime=(\S*)/) && ($default_wall{$name} = $1);
    (/MaxTime=(\S*)/)     && ($max_wall{$name} = $1);
    $default_wall{$name} = convertWallTime($default_wall{$name});
    $max_wall{$name} = convertWallTime($max_wall{$name});
  }
  close (IN);
  foreach my $part (keys %default_wall) {
    $PAR->{slurm_partitions}{$part}{default_time} = $default_wall{$part};
    $PAR->{slurm_partitions}{$part}{max_time} = $max_wall{$part};
  }
  #print Dumper($PAR->{slurm_partitions});
}
#==============================================================================
sub distributeCommands
# The commands have been parsed into an array, and the number of processes per node has been determined.  Now figure
# out how to distribute the commands to the command scripts.
{
  $PAR->{commands} = scalar(@{$SWARM->{COMMANDS}});

  foreach my $i (0 .. $#{$SWARM->{COMMANDS}}) {
    my ($sj,$cpu);
# No bundling, no packing
    if ($PAR->{b} == 1) {
      if (!$OPT{p}) {
        $sj = $i % $PAR->{maxarraysize};
        $cpu = 0;
      }
# No bundling, but yes packing
      else {
        #$sj = (floor($i/2)) % $PAR->{maxarraysize};
        #$cpu = $i % 2;
        $sj = (floor($i/$OPT{p})) % $PAR->{maxarraysize};
        $cpu = $i % $OPT{p};
      }
    }
# Yes bundling, but no packing
    else {
      if (!$OPT{p}) {
        $sj = (floor($i/$PAR->{b})) % $PAR->{maxarraysize};
        $cpu = 0;
      }
# Yes bundling, and yes packing
      else {
        #$sj = (floor($i/(2*$PAR->{b}))) % $PAR->{maxarraysize};
        #$cpu = $i % 2;
        $sj = (floor($i/$PAR->{b}/$OPT{p})) % $PAR->{maxarraysize};
        $cpu = floor($i/$PAR->{b}) % $OPT{p};
      }
    }
# Add the command number to the list
    push @{${$SWARM->{CMDLISTS}}[$sj][$cpu]},$i;
  }

  $PAR->{subjobs} = scalar(@{$SWARM->{CMDLISTS}});
}
#==============================================================================
sub report
{
# Report where the command files are written
  print "Command files written to $PAR->{tempdir}\n" if (($OPT{verbose} > 1) && (!$OPT{'no-scripts'}));
  my $len1 = length($#{$SWARM->{CMDLISTS}});
  my $len2 = length($#{$SWARM->{COMMANDS}});

# Report what modules will be loaded
  print "Loading modules $OPT{module}\n" if (($OPT{verbose} > 2) && ($OPT{module}));

# Report what modules will be loaded
  print "Using comment character $OPT{commentChar}\n" if (($OPT{verbose} > 2) && ($OPT{commentChar}));

# xxx - aaarghhh, what was this meant for?
# Fix OPT{p} and OPT{b} for single subjobs
  #if ($PAR->{subjobs} == 1) {
  #  $OPT{p} = $PAR->{commands} if (defined $OPT{p});
  #  $PAR->{b} = $PAR->{commands} if ($PAR->{b} > $PAR->{commands});
  #}

# update cpus-per-task and mem for single-threaded swarms
  if ((defined $OPT{p} && !$OPT{exclusive}) && !$ENV{SBATCH_EXCLUSIVE}) {
    $SLURMOPT{binary}{"cpus-per-task"} = $SLURMOPT{binary}{"cpus-per-task"}*$OPT{p};
    $SLURMOPT{binary}{"mem"} = $SLURMOPT{binary}{"mem"}*$OPT{p};
  } else {
    # if exclusive is specified in any way, always pass it along to sbatch
    $SLURMOPT{unary}{exclusive} = 1;
    # memory is not fully allocated by default, so add mem=0 in order to request all the memory on the node
    $SLURMOPT{binary}{"mem"} = 0;
    $PAR->{sbatch_options} .= " --mem=0 ";
    $SLURMOPT{binary}{"cpus-per-task"} = 1;
  }

# if only one cpu then set ntasks-per-core to 1 and remove cpus-per-task
  if ($SLURMOPT{binary}{"cpus-per-task"} == 1) {
    $SLURMOPT{binary}{"ntasks-per-core"} = 1;
    delete $SLURMOPT{binary}{"cpus-per-task"};
  } else {
    $SLURMOPT{binary}{"cpus-per-task"} = sprintf("%.0f", $SLURMOPT{binary}{"cpus-per-task"});
  }
  $SLURMOPT{binary}{"ntasks"} = 1; # xxx - not sure if this does anything or not

# xxx - what was this for?
# # Calculate total number of cpus allocated
#   $PAR->{cpus} = $PAR->{subjobs};
#   if (defined $OPT{p} && $OPT{t}) {
#     $PAR->{cpus} *= ($OPT{p} * $OPT{t})
#   } elsif (defined $OPT{p}) {
#     $PAR->{cpus} *= $OPT{p};
#   }
#   elsif ($OPT{t}) {
#     $PAR->{cpus} *= $OPT{t};
#   }

# Graphical representation of the swarm
  my $top = "(0tqq (B";
  my $pre = "(0x   ".$top;
#(0x   mqq (Btext # maybe in the future
#(0mqq (Btext

  my $outputfiles;
  print "-"x60,"\n"."SWARM\n" if ($OPT{verbose} > 3);
  foreach my $sj (0 .. $#{$SWARM->{CMDLISTS}}) {

# How many commands will be run in this subjob?
    my $num_cmds_in_subjob=0;
    $num_cmds_in_subjob += scalar(@{${$SWARM->{CMDLISTS}}[$sj][0]});
    $num_cmds_in_subjob += scalar(@{${$SWARM->{CMDLISTS}}[$sj][1]}) if (defined ${$SWARM->{CMDLISTS}}[$sj][1]);
    if ($OPT{verbose} > 3) {
      printf ("%ssubjob %${len1}d: %${len2}d command%s (%d cpu%s, %.2f gb)\n",
        $top,
        $sj,
        $num_cmds_in_subjob,
        write_s_if_needed($num_cmds_in_subjob),
        $SLURMOPT{binary}{"cpus-per-task"},
        write_s_if_needed($SLURMOPT{binary}{"cpus-per-task"}),
        ($SLURMOPT{binary}{"mem"}/1024),
      );
    }
    if ($OPT{verbose} > 4) {
      foreach my $cpu (0 .. $#{${$SWARM->{CMDLISTS}}[$sj]}) {
        if ($OPT{verbose} > 5) {
          my @tmp;
          foreach my $cmd (@{${$SWARM->{CMDLISTS}}[$sj][$cpu]}) { push @tmp,${$SWARM->{COMMANDS}}[$cmd]; }
          print $pre . (join ';',@tmp)."\n";
        }
        else {
          print $pre . (join ';',@{${$SWARM->{CMDLISTS}}[$sj][$cpu]})."\n";
        }
        $outputfiles++;
      }
    }
  }

  if ($OPT{verbose} > 3) {
    print "-"x60,"\n";
    printf "%${len1}d subjob%s, %${len2}d commands, %d output file%s\n",$PAR->{subjobs},write_s_if_needed($PAR->{subjobs}),$PAR->{commands},$outputfiles,write_s_if_needed($outputfiles);
  }
  if ($OPT{verbose} > 0) {
    print "$PAR->{commands} commands run in $PAR->{subjobs} subjob".write_s_if_needed($PAR->{subjobs}).", ";
    print "each command requiring $OPT{g} gb and $OPT{t} thread".write_s_if_needed($OPT{t});
    if ($OPT{p}) {
      print ", packing $OPT{p} processes per subjob";
    }
    if ($PAR->{b} > 1) {
      print ", running $PAR->{b} processes serially per subjob";
    }
    # elsif ((not defined $OPT{t}) || ($OPT{t} ne 'auto')) {
    elsif (not defined $OPT{t}) {
# allocating by core, not by cpu
      #my $cpus = $SLURMOPT{binary}{"cpus-per-task"};
      #($cpus%2) && $cpus++;
      #$cpus *= $PAR->{subjobs};
      #my $cores = $cpus/2;
      my $cores = $PAR->{subjobs};
      my $cpus = ceil($PAR->{commands} / $cores);
      print ", allocating $cores core".write_s_if_needed($cores)." and $cpus cpu".write_s_if_needed($cpus);
    }
    if ($PAR->{multinode}) {
      print " across $PAR->{multinode} nodes each";
    }
    if (defined $OPT{maxrunning}) {
      print ", with $OPT{maxrunning} subjobs running simultaneously";
    }
    print "\n";
  }

}
#==============================================================================
sub write_s_if_needed
{
  if (shift > 1) { return "s"; }
  else { return ""; }
}
#==============================================================================
sub insertLmodInit
# Insert two lines of code to load modules.  NOTE: This only works in a bash script.  It is meant to be
# inserted into the batch script, not the command scripts, which may use bash or tcsh to run.
{
  return unless $OPT{module};
  my $str;
  $str .= "source /usr/local/lmod/lmod/lmod/init/bash\n";
  $str .= "module load $OPT{module}\n";
  return $str;
}
#==============================================================================
sub writeCommandFile
{
  mkdir $PAR->{tempdir};
  chmod 02750,$PAR->{tempdir};
  append_to_tempdir_index(); # Record tempdir creation in the index
  my $len = length($#{$SWARM->{CMDLISTS}});
  my $content = "commandFileName=\"\$1\"\n";
# Walk through each subjob
  foreach my $sj (0 .. $#{$SWARM->{CMDLISTS}}) {
    my %fileContents;
    ##my $commandFileName = $PAR->{tempdir}."/cmd.$sj";
    my $commandFileName = "cmd.$sj";
# Walk through each commandline
    foreach my $cpu (0 .. $#{${$SWARM->{CMDLISTS}}[$sj]}) {
      foreach my $comm (@{${$SWARM->{CMDLISTS}}[$sj][$cpu]}) {
# Change command filename if packing
        ###$commandFileName = $PAR->{tempdir}."/cmd.$suffix"."_".($cpu) if $OPT{p};
        ##$commandFileName = $PAR->{tempdir}."/cmd.$sj"."_".($cpu) if $OPT{p};
        $commandFileName = "cmd.$sj"."_".($cpu) if $OPT{p};
        #$fileContents{$commandFileName} .= ${$SWARM->{COMMANDS}}[$comm]."\n";
        $fileContents{$commandFileName} .= ${$SWARM->{COMMANDS}}[$comm];
      }
    }
# Print the contents
    foreach my $file (sort keys %fileContents) {
      # if / elif block exceds some max if block size
      $content .= "if [[ \"\${commandFileName}\" == \"$file\" ]]; then\n$fileContents{$file}\nfi\n";
    }
  }
  printToFile($PAR->{singleCommandFullFileName}, $content, 0640);
}
#==============================================================================
sub printToFile
# Open file, write contents, flush and close.  'nuff said.
{
  my ($file,$contents,$mode) = @_;
  #my $fh = FileHandle->new;
  #if ($fh->open("> $file")) {
  #  print $fh $contents;
  #  $fh->flush;
  #  $fh->close;
  if (open(FH, ">", $file)) {
    print FH $contents;
    close(FH);
  }
  else { dieWithError("Can't write to $file\n"); }
  #chmod $mode,$file;
}
#==============================================================================
sub appendToFile
# Open file with append, write contents, flush and close.  'nuff said.
{
  my ($file,$contents) = @_;
  #my $fh = FileHandle->new;
  #if ($fh->open(">> $file")) {
  #  print $fh $contents;
  #  $fh->flush;
  #  $fh->close;
  if (open(FH, ">>", $file)) {
    print FH $contents;
    close(FH);
  }
  else { dieWithError("Can't write to $file\n"); }
}
#==============================================================================
sub writeBatchScript
#
# This is the file that sbatch calls.  Commands are normally run as a simple
# shell call, e.g.
#
#   bash [ commandfile ]
{
  my $fileContents;
  my $len = length($#{$SWARM->{CMDLISTS}});
  my $len3 = length($OPT{p}) if $OPT{p};
  $fileContents .= "#!/bin/bash\n";

# The swarm.batch file loads the modules, and the command scripts will inherit the environment.  Thie
# can be screwed up if the user fiddles with the environment within the commands.
  $fileContents .= insertLmodInit();

# Generate the rest of the batch script.  NOTE: The path to the temporary directory is hard-coded in
# the swarm.batch script.  This allows a swarm to be rerun, albeit with the correct sbatch options.
# These can be found in the swarm logfile.
  $fileContents .= "d=$PAR->{tempdir}\n";
  $fileContents .= "logd=$OPT{logdir}\n";

# hook for top level swarm-tools scripts that use this frequently.
# in case the user is doing the evil thing and running lots of swarms in the same dir,
#   do not try to create another job_id.txt if it already exists.
# this has to be done here incase we are using sbatch in wait (blocking) mode.
  $fileContents .= "job_id_fn=\${logd}/job_id.txt\n";
  $fileContents .= "if [[ ! -s \${job_id_fn} && \"\${SLURM_ARRAY_TASK_ID}\" == \"0\" ]]; then\n";
  $fileContents .= "echo \${SLURM_ARRAY_JOB_ID} > \${job_id_fn}\n";
  $fileContents .= "fi\n";

# insert a small random sleep so that jobs in large job arrays do not all start simultaneously
  #$fileContents .= "sleep \$((RANDOM % 11 + 3))\n"; # generates same integer for simultaneously started scripts
  $fileContents .= "R=\$(date +%N)\$\$; R=\$((R % 31 + 1)); echo sleeping \$R s; sleep \$R\n";

# Write the command executed block at the top of the output
  my $ce_top = "COMMAND EXECUTED: \"";
  my $ce_bot = "\"";

  $fileContents .= "exitcode=\$(($OPT{p}+1))\n"; # would indicate that command file is missing somehow
  $fileContents .= "if [[ -s \${d}/$PAR->{singleCommandFileName} ]]; then\n";
  $fileContents .= "exitcode=0\n";

# Run the commands in series on a single node
  if ($OPT{p}) {
    foreach my $i (0 .. $OPT{p}-1) {
      ##$fileContents .= "[[ -s \${d}/cmd.\${SLURM_ARRAY_TASK_ID}_$i ]] && ( /bin/echo '$ce_top' && /bin/cat \${d}/cmd.\${SLURM_ARRAY_TASK_ID}_$i && /bin/echo '$ce_bot' && $PAR->{shell} \${d}/cmd.\${SLURM_ARRAY_TASK_ID}_$i ";
      $fileContents .= "if grep -q \\\"cmd.\${SLURM_ARRAY_TASK_ID}_$i\\\" \${d}/$PAR->{singleCommandFileName}; then\n";
      my $echo = "${ce_top}cmd.\${SLURM_ARRAY_TASK_ID}_$i${ce_bot}";
      $fileContents .= "( /bin/echo $echo && $PAR->{shell} \${d}/$PAR->{singleCommandFileName} cmd.\${SLURM_ARRAY_TASK_ID}_$i ";
# Determine output/error redirects
      if ($OPT{"merge-output"}) {
        $fileContents .= ">& \${logd}/$PAR->{'job-name'}_\${SLURM_ARRAY_JOB_ID}_\${SLURM_ARRAY_TASK_ID}_$i.o ";
      }
      else {
        if ($OPT{noout}) {
          $fileContents .= "1> /dev/null ";
        }
        else {
          $fileContents .= "1> \${logd}/$PAR->{'job-name'}_\${SLURM_ARRAY_JOB_ID}_\${SLURM_ARRAY_TASK_ID}_$i.o ";
        }
        if ($OPT{noerr}) {
          $fileContents .= "2> /dev/null ";
        }
        else {
          $fileContents .= "2> \${logd}/$PAR->{'job-name'}_\${SLURM_ARRAY_JOB_ID}_\${SLURM_ARRAY_TASK_ID}_$i.e ";
        }
      }
      $fileContents .= ") &\n";
      $fileContents .= "fi\n";
    }
    $fileContents .= "fi\n";
    $fileContents .= "wait\n";
    if ($OPT{'check-msg'}) {
      my $j = $OPT{p}-1;
      $fileContents .= "for i in {0..$j}; do\n";
      #$fileContents .= "if [[ -s \${d}/cmd.\${SLURM_ARRAY_TASK_ID}_\$i ]] &&";
      $fileContents .= "if [[ -s \${d}/$PAR->{singleCommandFileName} ]]; then\n";
      $fileContents .= "  if grep -q \\\"cmd.\${SLURM_ARRAY_TASK_ID}_\$i\\\" \${d}/$PAR->{singleCommandFileName}; then\n";
      $fileContents .= "    if tail \${logd}/$PAR->{'job-name'}_\${SLURM_ARRAY_JOB_ID}_\${SLURM_ARRAY_TASK_ID}_\$i.o";
      $fileContents .= " | grep -q 'Twas brillig, and the slithy toves'; then\n";
      $fileContents .= "      exitcode=\$((exitcode+0))\n";
      ##$fileContents .= "elif [[ -s \${d}/cmd.\${SLURM_ARRAY_TASK_ID}_\$i ]]; then\n";
      #$fileContents .= "elif [[ -s \${d}/$PAR->{singleCommandFileName} ]]; then\n";
      $fileContents .= "    else\n";
      $fileContents .= "      exitcode=\$((exitcode+1))\n";
      $fileContents .= "    fi\n";
      $fileContents .= "  fi\n";
      $fileContents .= "fi\n";
      $fileContents .= "done\n";
    }
    # else {
    #   #$fileContents .= "exitcode=0\n";
    # }
  }
  else {
    ##$fileContents .= "/bin/echo '$ce_top' && /bin/cat \${d}/cmd.\${SLURM_ARRAY_TASK_ID} && /bin/echo '$ce_bot' && $PAR->{shell} \${d}/cmd.\${SLURM_ARRAY_TASK_ID}\n";
    my $echo = "${ce_top}cmd.\${SLURM_ARRAY_TASK_ID}${ce_bot}";
    $fileContents .= "/bin/echo $echo && $PAR->{shell} \${d}/$PAR->{singleCommandFileName} cmd.\${SLURM_ARRAY_TASK_ID}\n";
# Capture final exit code
    $fileContents .= "exitcode=\$?\n";
    $fileContents .= "fi\n";
  }

  $fileContents .= "exit \$exitcode\n"; # Exit with the final exit code from the given command

# Print the batch file
  printToFile($PAR->{batchfile},$fileContents,0640);
}
#==============================================================================
sub submitSlurm
{
  $PAR->{sbatch_options} .= "--array=0-$#{$SWARM->{CMDLISTS}}";
  $PAR->{sbatch_options} .= '%'.$OPT{maxrunning} if (defined $OPT{maxrunning});
  $PAR->{sbatch_options} .= " --job-name=".$PAR->{"job-name"} unless ($SLURMOPT{binary}{"job-name"});

# output and error handled in the batch script
  if ($OPT{p}) {
    $PAR->{sbatch_options} .= " --output=/dev/null";
    $PAR->{sbatch_options} .= " --error=/dev/null";
    # !!!DO NOT do this, all job arrays will try to write to the same .o and .e file!!!
    #$PAR->{sbatch_options} .= " --output $OPT{logdir}"."/sbatch.o";
    #$PAR->{sbatch_options} .= " --error $OPT{logdir}"."/sbatch.e";
  }
  else {
    # !!! Bug, does not actually merge, BUT DO NOT do this, all job arrays would write to the same .o file!!!
    # if ($OPT{"merge-output"}) {
    #   $PAR->{sbatch_options} .= " --output=".$OPT{logdir}."/".$PAR->{"job-name"}."_\%A_\%a.o";
    # }
    # else {
      #if ($OPT{noout}) {
        $PAR->{sbatch_options} .= " --output=/dev/null";
      #}
      #else {
      #  $PAR->{sbatch_options} .= " --output=".$OPT{logdir}."/".$PAR->{"job-name"}."_\%A_\%a.o";
      #}
      #if ($OPT{noerr}) {
        $PAR->{sbatch_options} .= " --error=/dev/null";
      #}
      #else {
      #  $PAR->{sbatch_options} .= " --error=".$OPT{logdir}."/".$PAR->{"job-name"}."_\%A_\%a.e";
      #}
    # }
  }

# slurm options
  foreach my $i (sort keys %{$SLURMOPT{unary}}) {
    $PAR->{sbatch_options} .= " --$i" if ($SLURMOPT{unary}{$i});
  }
  foreach my $i (sort keys %{$SLURMOPT{binary}}) {
    $PAR->{sbatch_options} .= " --${i}=$SLURMOPT{binary}{$i}" if ($SLURMOPT{binary}{$i});
  }
  if ($SBATCHOPT) {
    $PAR->{sbatch_options} .= " ".$SBATCHOPT;
  }

  print "sbatch $PAR->{sbatch_options} $PAR->{batchfile}\n" if ($OPT{verbose} > 1);
  unless ($OPT{'no-run'}) {
    if (!-d $OPT{logdir}) {
      make_path($OPT{logdir}) || dieWithError("can't create logdir $OPT{logdir}");
    }
    elsif (!-w $OPT{logdir}) {
      dieWithError("can't write to logdir $OPT{logdir}");
    }
    my $slurm_response = `sbatch $PAR->{sbatch_options} $PAR->{batchfile}`;
    print $slurm_response;
    #if ($slurm_response=~/^(\d+)$/) {
    if ($slurm_response=~/Submitted batch job (\d+)/) {
      $PAR->{jobid} = $1;
    }
    else {
      dieWithError("Something went wrong with sbatch!  I don't know the jobid!");
    }
  }
}
#==============================================================================
sub createSymlink
# Create a symlink to the temporary directory with the jobid
{
  my $num;
  if ($PAR->{jobid}) {
    symlink ("$PAR->{tempdir}","$PAR->{basedir}/$PAR->{jobid}");
  }
}
#==============================================================================
sub parseCommands
{
  open(COMMANDFILE, "$PAR->{Commandfile}") || dieWithError("Can't read $PAR->{Commandfile}: $!");
  my @COMMANDS = evaluateCommands(mergeLineContinuations(<COMMANDFILE>));
  close COMMANDFILE;
  foreach (@COMMANDS) {
    chomp;
    s/\r//g;         # remove carriage returns
    next if /^\s*$/; # ignore blank lines
    if (!$OPT{nocomment}) {
      next if /^\s*$PAR->{commentChar}/; # remove comment lines
      s/$PAR->{commentChar}.*//g; # remove comment lines
    }
    s/[\s;]+$//;     # don't allow final semicolons or spaces
    push @{$SWARM->{COMMANDS}},$_;
  }

# Make sure that the swarmfile actually has commands in it!
  if ((not defined $SWARM->{COMMANDS}) || (ref($SWARM->{COMMANDS}) != /ARRAY/) || (@{$SWARM->{COMMANDS}} < 1)) {
    dieWithError("No commands in swarmfile $PAR->{Commandfile}");
  }
}
#==============================================================================
sub evaluateCommands
{
# evaluate test conditions if present
  my @tmp = @_;
  return @tmp unless $OPT{evaluate};
  my @filtered;
  foreach (@tmp) {
    if (m/^(.*?)\s*#EVAL(.*)$/) {
      my $line = $1;
      my (undef,$fn) = tempfile('tmpXXXXXXXX',OPEN => 0,DIR=>'/tmp',SUFFIX=>'.sw');
      my $eval = $2;
      open FILE, ">$fn";
      if ($PAR->{shell} eq '/bin/bash') {
        print FILE "if [ $eval ] ; then echo 1 ; else echo 2 ; fi\n";
      }
      elsif ($PAR->{shell} eq '/bin/tcsh') {
        print FILE "if ( $eval ) then\necho 1\nelse\necho 2\nendif\n";
      }
      close FILE;
      chomp(my $ret = `$PAR->{shell} $fn 2>&1`);
      unlink $fn;
      if ($ret == 1) {
        push @filtered,"$line\n";
      }
      elsif ($ret == 2) {
# drop the command
      }
      else {
        dieWithError("commandline evaluation failure:\n$ret");
      }
    }
    else {
      push @filtered,$_;
    }
  }
  return @filtered;
}
#==============================================================================
sub mergeLineContinuations
# If a swarmfile has line continuation markers (one or more spaces, followed
# by a single backslash, immediately followed by end-of-line), then the line
# will be continued with the next line.  Suggested by Wolfgang Resch, 11/29/12.
{
  my @lines = @_;
  my @merged;
  my $cmd;
  my $i;
  foreach my $l (@lines) {
    $i++;
    chomp $l;
    if ($l=~/\\\s*$/) { # attempt at line continuation
      if ($l=~/ \\$/) { # only strict, proper format is allowed
        $cmd .= " $`";
      } else {
        dieWithError("bad line continuation format: line $i of $OPT{f}");
      }
    }
    else {
      $cmd .= " $l";
      dieWithError("last line of $OPT{f} cannot have line continuation") if ($cmd =~/\\$/);
      push @merged,$cmd;
      undef $cmd;
    }
  }
  dieWithError("last line of $OPT{f} cannot have line continuation") if (defined $cmd);
  return @merged;
}
#===============================================================================
	sub getCommandLineOptions
	{
	# capture command line

	  $PAR->{commandLine} = $0;
	  my $quotenext;
	  foreach my $arg (@ARGV) {
	    if ($quotenext) {
	      $PAR->{commandLine} .= " '$arg'";
	      undef $quotenext;
	      next;
	    }
	    $quotenext=1 if ($arg=~/^--sbatch$/);
	    $PAR->{commandLine} .= " $arg";
	  }

	  GetOptions(

	# standard swarm options
	    "f=s"               => \$OPT{f},
	    "file=s"            => \$OPT{f},
	    "b=i"               => \$OPT{b},
	    "bundle=i"          => \$OPT{b},
	    # "autobundle"        => \$OPT{autobundle},
	    "g=f"               => \$OPT{g},
	    "gb-per-process=f"  => \$OPT{g},
	    "t=s"               => \$OPT{t},
	    "threads-per-process=s" => \$OPT{t},
	    "p=i"               => \$OPT{p},      # run 2 commands per core for single threaded bundled swarms
	    "processes-per-subjob=i"  => \$OPT{p},      # run 2 commands per core for single threaded bundled swarms
    "exclusive"         => \$OPT{exclusive},
    "usecsh"            => \$OPT{usecsh},    # use tcsh shell instead of bash
    "comment-char=s"    => \$OPT{commentChar}, # comment character
    "no-comment"        => \$OPT{nocomment}, # no comment character
    "evaluate"          => \$OPT{evaluate}, # only keep commands that evaluate as true
    # "noht"              => \$OPT{noht},     # no hyperthreading
    'm=s'               => \$OPT{module},  # modules are comma delimited
    'module=s'          => \$OPT{module},  # modules are comma delimited
    'err-exit'          => \$OPT{errexit}, # include -e in the shell (requires bash)

# special stuff, handle with care
    "noout"             => \$OPT{noout},#  completely throw away STDOUT
    "noerr"             => \$OPT{noerr},#  completely throw away STDERR
    "logdir=s"          => \$OPT{logdir},# directory to which .o and .e files are written
    "merge-output"      => \$OPT{"merge-output"},# merge stdout and stderr into .o

# interactive stuff
    "h"                 => \$OPT{h},
    "help"              => \$OPT{h},
    "no-scripts"        => \$OPT{'no-scripts'}, # don't print scripts (requires debug}
    "debug"             => \$OPT{debug},     # --verbose=1, --no-run
    "devel"             => \$OPT{devel},     # --verbose=2, --no-run, --no-scripts
    "v=i"               => \$OPT{verbose},   # verbosity level, default = 1
    "verbose=i"         => \$OPT{verbose},   # verbosity level, default = 1
    "silent"            => \$OPT{silent},   # verbosity level = 0

# hidden options
    "no-run"            => \$OPT{'no-run'},  # don't actually run
    "no-log"            => \$OPT{'no-log'},  # don't actually write to logfile
    "logfile=s"         => \$OPT{logfile},   # alternate logfile
    "maxarraysize=i"    => \$OPT{maxarraysize}, # for testing
    "maxrunning=i"      => \$OPT{maxrunning}, # limit the number of running jobs, for testing
    "check-msg"         => \$OPT{'check-msg'}, # report FAIL if special message not at end

# sbatch options (specific)
    "hint=s"            => \$SLURMOPT{binary}{hint},
    "dependency=s"      => \$SLURMOPT{binary}{dependency},
    "partition=s"       => \$SLURMOPT{binary}{partition},
    "time=s"            => \$SLURMOPT{binary}{time},
    # "exclusive"         => \$SLURMOPT{unary}{exclusive},
    "L=s"               => \$SLURMOPT{binary}{licenses},
    "licenses=s"        => \$SLURMOPT{binary}{licenses},
    "J=s"               => \$SLURMOPT{binary}{"job-name"},
    "job-name=s"        => \$SLURMOPT{binary}{"job-name"},
    "gres=s"            => \$SLURMOPT{binary}{gres},
    "qos=s"             => \$SLURMOPT{binary}{qos},

# sbatch option (general)
    "sbatch=s"          => \$SBATCHOPT, # a catch all for all other sbatch options

  ) || exit 1;

  print_options() if $OPT{h};

  # if ($OPT{autobundle}) { print STDERR "WARNING: --autobundle has been deprecated\n"; }

  dieWithError("Specify a partition, default no longer supported") if (not defined $SLURMOPT{binary}{partition});
# # Default partition
#   if (not defined $SLURMOPT{binary}{partition}) {
#     if (defined $ENV{SBATCH_PARTITION}) {
#       $SLURMOPT{binary}{partition} = $ENV{SBATCH_PARTITION};
#     }
#     elsif (defined $SBATCHOPT) {
#       if ($SBATCHOPT=~/(^\-\-partition\s*=?\s*)(\w+)/) {
#         $SLURMOPT{binary}{partition} = $2;
#         $SBATCHOPT=~s/${1}${2}//g;
#       }
#       elsif ($SBATCHOPT=~/(^\-p\s*=?\s*)(\w+)/) {
#         $SLURMOPT{binary}{partition} = $2;
#         $SBATCHOPT=~s/${1}${2}//g;
#       }
#       elsif ($SBATCHOPT=~/( \-\-partition\s*=?\s*)(\w+)/) {
#         $SLURMOPT{binary}{partition} = $2;
#         $SBATCHOPT=~s/${1}${2}//g;
#       }
#       elsif ($SBATCHOPT=~/( \-p\s*=?\s*)(\w+)/) {
#         $SLURMOPT{binary}{partition} = $2;
#         $SBATCHOPT=~s/${1}${2}//g;
#       }
#       else {
#         $SLURMOPT{binary}{partition} = "norm";
#       }
#     }
#     else {
#       $SLURMOPT{binary}{partition} = "norm";
#     }
#   }

# Look to see if this is a multinode job
  my $nodes;
  if (defined $SBATCHOPT) {
    if ($SBATCHOPT=~/^\-\-nodes\s*=?\s*(\d+)/) { $nodes = $1; }
    elsif ($SBATCHOPT=~/ \-\-nodes\s*=?\s*(\d+)/) { $nodes = $1; }
    elsif ($SBATCHOPT=~/^\-N\s*=?\s*(\d+)/) { $nodes = $1; }
    elsif ($SBATCHOPT=~/ \-N\s*=?\s*(\d+)/) { $nodes = $1; }
  }
  $PAR->{multinode} = $nodes if ($nodes && $nodes > 1);

# Be quiet!
  $OPT{verbose} = 0 if $OPT{silent};

# development run
  if ($OPT{devel}) {
    $OPT{'no-scripts'} = 1;
    $OPT{'no-run'} = 1;
    $OPT{'no-log'} = 1;
    $OPT{debug} = 1;
    $OPT{verbose} = 3 unless (defined $OPT{verbose});
  }
  elsif ($OPT{debug}) {
    $OPT{verbose} = 2;
    $OPT{'no-run'} = 1;
    $OPT{'no-log'} = 1;
  }

# $OPT{'no-log'} override
  if ((defined $OPT{logfile}) && ($OPT{logfile} ne $PAR->{logfile})) {
    undef $OPT{'no-log'};
    $PAR->{logfile} = $OPT{logfile};
  }

# Default verbosity
  $OPT{verbose} = 0 if (not defined $OPT{verbose});

# Create a temporary name for the batch script and command script directory.
  (undef,$PAR->{tempname}) = tempfile('XXXXXXXXXX',OPEN => 0);
  $PAR->{tempdir} = "$PAR->{basedir}/$PAR->{tempname}";
  $PAR->{batchfile} = $PAR->{tempdir}."/swarm.batch";
  $PAR->{singleCommandFileName} = "commands";
  $PAR->{singleCommandFullFileName} = $PAR->{tempdir}."/commands";

# Be chatty
  print "basedir = $PAR->{basedir}\n" if ($OPT{verbose} > 4);
  print "script dir = $PAR->{tempdir}\n" if ($OPT{verbose} > 4);

# avoid stupidness
  $OPT{b}=1 if ((not defined $OPT{b}) || ($OPT{b} <= 1));
  $PAR->{b} = $OPT{b};

# set cpus-per-task or ntasks-per-node
  if ($OPT{t}) {
    # if ($OPT{t} eq "auto") {
    #   $SLURMOPT{binary}{"cpus-per-task"} = 32;
    # } else {
# Don't be stupid
      #dieWithError("-t must be either a number or \"auto\"") if !($OPT{t}=~/^\d+$/ || $OPT{t} eq "auto");
      #dieWithError("-t must be either a number >=1") if ($OPT{t} < 1);
      # dieWithError("-t must be either a number or \"auto\"")
      #   if !($OPT{t}=~/^[+-]?([0-9]+([.][0-9]*)?|[.][0-9]+)$/ || $OPT{t} eq "auto");
      dieWithError("-t must be either an integer number")
        if !($OPT{t}=~/^[+-]?([0-9]+([.][0-9]*)?|[.][0-9]+)$/);
      dieWithError("-t must be a number > 0") if ($OPT{t} <= 0);
      $SLURMOPT{binary}{"cpus-per-task"} = $OPT{t};
    # }
  }
  else {
    $OPT{t} = 1;
    $SLURMOPT{binary}{"cpus-per-task"} = 1;
  }

# And of course because we allocate per core, rather than per cpu, we need to adjust cpus-per-task
  #$SLURMOPT{binary}{"cpus-per-task"} = 2 if ($SLURMOPT{binary}{"cpus-per-task"} == 1);

## pack only allowed for single threaded swarms
#  if ($OPT{t} && $OPT{p}) {
#    if (($OPT{t} > 1) && ($OPT{p} > 1)) {
#      dieWithError("-t is for multi-threaded or multi-node commands, -p is for single-threaded commands.  Use one or the other!");
#    }
#  }
#  undef $OPT{p} if ($OPT{p} <= 1);
## Don't allow p to be more than 2
#  dieWithError("-p can't be more than 2.") if ($OPT{p} > 2);

# # Don't allow hyperthreading, which implies no packing
#   $SLURMOPT{binary}{"threads-per-core"} = 1 if ($OPT{noht});

# Set qos
  if ($ENV{SBATCH_QOS} && (not defined $SLURMOPT{binary}{qos})) {
     $SLURMOPT{binary}{qos} = $ENV{SBATCH_QOS};
  }

# # Special for exclusivity
#   if ($SLURMOPT{unary}{exclusive}) {
#     $SLURMOPT{binary}{"ntasks-per-node"} = 1;
#     delete $SLURMOPT{binary}{"ntasks-per-core"};
#   }
#   elsif ($ENV{SBATCH_EXCLUSIVE}) {
#     $SLURMOPT{unary}{exclusive}=1;
#     $SLURMOPT{binary}{"ntasks-per-node"} = 1;
#     delete $SLURMOPT{binary}{"ntasks-per-core"};
#   }

  if (defined $OPT{g}) { # assign to --mem, converted to MB
    dieWithError("-g must be between 0.01 and ".$PAR->{maxmemsize})
      if (($OPT{g} <= 0.01) || ($OPT{g} > $PAR->{maxmemsize}));
    #if (($OPT{g} > 248) && ($SLURMOPT{binary}{partition} ne "largemem")) {
    #  dieWithError("-g $OPT{g} requires --partition largemem");
    #}
  }
  else {
    $OPT{g} = 1.5;
  }
  #$SLURMOPT{binary}{"mem"} = ceil($OPT{g}*1024);
  $SLURMOPT{binary}{"mem"} = floor($OPT{g}*1024);

# After getopts, argv should be -1 for this script.
  dieWithError("excess commandline arguments (@ARGV). See $PAR->{programname} --help") if ($#ARGV > -1 || $#ARGV < -1);

# Also, swarm MUST be called with -f option
  dieWithError("must specify '-f cmdfile'  See $PAR->{programname} --help") if !$OPT{f};

  $PAR->{Commandfile} = $OPT{f};

# Swarmfile must be a file
  dieWithError("where is swarmfile?") if (! -f $OPT{f});

# The swarmfile must not exceed 100MB in size.
  #dieWithError("swarmfile must not exceed 100MB in size") if ((stat($OPT{f}))[7] > (100*1024*1024));

# Check validity of $OPT{force}
#  if (@{$OPT{force}}) {
#    dieWithError("must specify processes per node (--force [nt] [ntasks-per-node])") if (${$OPT{force}}[1] !~/^\d+$/);
#  }

# choose shell to run under
  $PAR->{shell} = ($OPT{usecsh}) ? "/bin/tcsh" : "/bin/bash";

# modify shell if wanted
  $PAR->{shell} .= " -e" if ($OPT{errexit});

# set commentChar
  $PAR->{commentChar} = substr($OPT{commentChar},0,1) if $OPT{commentChar};

# rewrite resource list
#  if (defined $OPT{R}) {
#    my @tmp;
#    foreach my $i (split /,/,$OPT{R}) {
#      if ($i eq 'gpfs') { $PAR->{gpfs}=1; } # set gpfs resource
#      elsif ($i eq 'gpu2050') { $PAR->{gpu2050}=1; } # set gpu resource
#      else { push @tmp,$i; }
#    }
#    $OPT{R} = join ',',@tmp;
#  }

# Convert module from comma-delimited list to space-delimited list
  if ($OPT{module}) {
    my @tmp = split /,/,$OPT{module};
    $OPT{module} = join " ",@tmp;
  }

# Determine job-name
  if ($SLURMOPT{binary}{'job-name'}) {
    $PAR->{"job-name"} = $SLURMOPT{binary}{'job-name'};
  }
  elsif ($ENV{SBATCH_JOB_NAME}) {
    $SLURMOPT{binary}{'job-name'} = $ENV{SBATCH_JOB_NAME};
    $PAR->{"job-name"} = $SLURMOPT{binary}{'job-name'};
  }
  else {
    $PAR->{"job-name"} = "swarm";
  }

# Make sure that the logdir can be written to
  if (defined $OPT{logdir}) {
    isDirCreateable($OPT{logdir}) || dieWithError("can't write to $OPT{logdir}");
  }
  else {
    $OPT{logdir} = $PAR->{pwd};
  }

# Set time
  if (defined $ENV{SBATCH_TIMELIMIT}) {
    $SLURMOPT{binary}{time}=$ENV{SBATCH_TIMELIMIT};
  }

# Override default maxarraysize if needed
  $PAR->{maxarraysize} = $OPT{maxarraysize} if $OPT{maxarraysize};

# Be reasonable
  if ((defined $OPT{maxrunning}) && ($OPT{maxrunning} < 1)) {
    undef $OPT{maxrunning};
  }

# noout and noerr are incompatible with merge-output
  if ($OPT{"merge-output"}) {
    if ($OPT{noout} || $OPT{noerr}) {
      dieWithError("--noout and --noerr are incompatible with --merge-output");
    }
  }
}
#==============================================================================
sub print_options
{
  print <<EOF;
Usage: swarm [swarm options] [sbatch options]

  -f,--file [file]       name of file with list of command lines to execute,
                         with a single command line per subjob

  -g,--gb-per-process    gb per process (can be fractions of GB, e.g. 3.5)
  [float]

  -t,                    threads per process (must be an integer).
  --threads-per-process
  [int]

  -p,                    processes per subjob (default = 1).
  --processes-per-subjob
  [int]

  -b,--bundle [int]      bundle more than one command line per subjob and run
                         sequentially (this automatically multiplies the time
                         needed per subjob)

  --usecsh               use tcsh as the shell instead of bash
  --err-exit             exit the subjob immediately on first non-zero exit status

  -m, --module           provide a list of environment modules to load
                         prior to execution (comma delimited)

  --no-comment           don't ignore text following comment character $PAR->{commentChar}
  -c, --comment-char [chr]
                         use something other than $PAR->{commentChar} as the comment character

  --merge-output         combine STDOUT and STDERR into a single file per subjob (.o)
  --logdir               directory to which .o and .e files are to be written
                         (default is current working directory)

  --maxrunning [int]     limit the number of simultaenously running subjobs

  --exclusive            always request full node resources,
                         no matter --threads-per-process or --processes-per-subjob

Development options:

  -h, --help             print this help message
  --no-scripts           don't create temporary swarm scripts (with --debug
                         or --devel)
  --debug                don't actually run
  --devel                combine --debug and --no-scripts, and be very chatty
  -v, --verbose [int]    can range from 0 to 4, with 4 the most verbose
  --silent               don't give any feedback, just jobid

sbatch options:

  -J, --job-name [str]   set the name of the job
  --dependency [str]     set up dependency (i.e. run swarm before or after)
  --time [str]           change the walltime for each subjob (default is
                         04:00:00, or 4 hours)
  -L,--licenses [str]    obtain software licenses (e.g. --licenses=matlab)
  --partition [str]      change the partition (default is norm)
  --gres [str]           set generic resources for swarm
  --qos [str]            set quality of service for swarm

Other sbatch options

  --sbatch [string]      add sbatch-specific options to swarm.  These options
                         will be added last, which means that swarm options
                         for allocation of cpus and memory take precedence.

Environment variables

  The following environment variables will affect how sbatch allocates
  resources:

  SBATCH_JOB_NAME        Same as --job-name
  SBATCH_PARTITION       Same as --partition
  SBATCH_QOS             Same as --qos
  SBATCH_TIMELIMIT       Same as --time

EOF
  exit;
}
#==============================================================================
sub dieWithError
{
  my $message = shift;
  die "ERROR: $message\n";
}
#==============================================================================
sub writeLog
# log some useful information
{
  my $x = $PAR->{sbatch_options};   # Make Susan happy
  $x=~s/%A/$PAR->{jobid}/g;

  my $fileContents = "date=".$PAR->{date}            ."; "
          . "host="       .$PAR->{host}            ."; "
          . "jobid="      .$PAR->{jobid}           ."; "
          . "user="       .$PAR->{user}            ."; "
          . "pwd="        .$PAR->{pwd}             ."; "
          . "ncmds="      .$PAR->{commands}        ."; "
          . "soptions="   .$x                      ."; "
          . "njobs="      .$PAR->{subjobs}         ."; "
          . "tempname="   .$PAR->{tempname}        ."; "
          . "job-name="   .$PAR->{'job-name'}      ."; "
          . "command="    .$PAR->{commandLine}     ."\n";

  appendToFile($PAR->{logfile},$fileContents);
  chmod 0666, $PAR->{logfile};
}
#==============================================================================
sub writesLog
# log some useful information
{
  my $x = $PAR->{sbatch_options};   # Make Susan happy
  $x=~s/%A/$PAR->{jobid}/g;

  my $fileContents =   $PAR->{date}            ."; "
          . ""        .$PAR->{time}            ."; "
          . ""        .$PAR->{host}            ."; "
          . "SUBM["   .$PAR->{jobid} ."]"      ."; "
          . ""        .$PAR->{user}            ."; "
          . ""        .$PAR->{pwd}             ."; "
          . "sbatch " .$x                      ."\n";

  appendToFile($PAR->{slogfile},$fileContents);
  chmod 0666, $PAR->{slogfile};
}
#==============================================================================
sub isDirCreateable
{
  my $path = shift;
  my $str = File::Spec->rel2abs($path); # convert path to absolute
  while (!-d $str) { $str =~s/\/[^\/]*$//; }
  return 1 if (-w $str);
}
#==============================================================================
sub validatePartition
# Don't let the use choose an unknown or invalid partition
{
  my @names = (sort keys %{$PAR->{slurm_partitions}});
  foreach my $part (split /,/,$SLURMOPT{binary}{partition}) {
    dieWithError("Unknown partition '$part'!") unless (grep /^$part$/,@names);
    dieWithError("Partition '$part' is only valid for multinode jobs") if (($part eq 'ibddr') && !$PAR->{multinode});
    dieWithError("Partition '$part' is only valid for multinode jobs") if (($part eq 'ibfdr') && !$PAR->{multinode});
    dieWithError("Partition '$part' is only valid for multinode jobs") if (($part eq 'ibqdr') && !$PAR->{multinode});
  }
}
#==============================================================================
sub adjustTime
# The timelimit must be changed to account for bundling and/or folding
{
# # Don't bother if partition is unlimited
#   return if ($SLURMOPT{binary}{partition} eq "unlimited");

# Account for multiple partitions
  $PAR->{default_time} = 999999999999; # really long time
  $PAR->{max_time} = 999999999999; # really long time
  foreach my $part (split /,/,$SLURMOPT{binary}{partition}) {
    my $part_found;
    foreach my $name (sort keys %{$PAR->{slurm_partitions}}) {
      if ($name eq $part ) {
        my $i = $PAR->{slurm_partitions}{$name};
        $part_found=1;
        my $t = ($i->{default_time}*60); # time is in minutes
        $PAR->{default_time} = $t if ($t < $PAR->{default_time});
        $t = ($i->{max_time}*60); # time is in minutes
        $PAR->{max_time} = $t if ($t < $PAR->{max_time});
      }
    }
    ($part_found) || dieWithError("undefined time limit for $SLURMOPT{binary}{partition} partition!");
  }

# Find requested_time from user
  if (defined $SLURMOPT{binary}{time}) {
    $PAR->{requested_time} = clock_to_seconds($SLURMOPT{binary}{time});
  }
  else {
    $PAR->{requested_time} = $PAR->{default_time};
  }

# xxx - was this only for bundling? did not see the point
## Do we need to adjust the time?  With folding, we now have to determine this on a per-subjob basis
#  my $max_adjusted_time = 0;
#  foreach my $sj (0 .. $#{$SWARM->{CMDLISTS}}) {
#    my $max_cmds_in_subjob = scalar(@{${$SWARM->{CMDLISTS}}[$sj][0]});
#    if (defined ${$SWARM->{CMDLISTS}}[$sj][1]) {
#      my $z = scalar(@{${$SWARM->{CMDLISTS}}[$sj][1]});
#      if ($z && ($z > $max_cmds_in_subjob)) {
#        $max_cmds_in_subjob = $z;
#      }
#    }
#    my $adjusted_time = $PAR->{requested_time} * $max_cmds_in_subjob;
#    $max_adjusted_time = $adjusted_time if ($max_adjusted_time < $adjusted_time);
#    push @{$SWARM->{SUBJOB_TIME}},$adjusted_time;
#  }

# forget about all this time adjustment stuff, just use the time specified by the user
#  my $max_adjusted_time = $PAR->{max_time}; # do not do this, allow time to come from user
  my $max_adjusted_time = $PAR->{requested_time};

# Die if the max_adjusted_time is too great
  print "time $max_adjusted_time max time $PAR->{max_time} time\n";
  dieWithError("Total time for bundled commands is greater than partition walltime limit.\nTry lowering the time per command (--time=".seconds_to_clock($PAR->{requested_time})."), lowering the bundle factor\n(if not autobundled), picking another partition, or splitting up the swarmfile.") if ($max_adjusted_time > $PAR->{max_time});

# Set time to the maximum amount
  $SLURMOPT{binary}{time} = seconds_to_clock($max_adjusted_time);
}
#==============================================================================
sub seconds_to_clock
# converts seconds to clock time (D*-HH:MM:SS)
{
  my($time) = @_;
  my($sec) = 0;
  my($min) = 0;
  my($hrs) = 0;
  my($day) = 0;
  $sec = $time;
  $min = $sec / 60;
  $sec = $sec % 60;
  if ($min > 60) {
    $hrs = $min / 60;
    $min = $min % 60;
    if ($hrs > 24) {
      $day = $hrs / 24;
      $hrs = $hrs % 24;
      return sprintf ("%d-%02d:%02d:%02d",$day,$hrs,$min,$sec);
    }
    else { return sprintf ("%02d:%02d:%02d",$hrs,$min,$sec); }
  }
  else { return sprintf ("%02d:%02d",$min,$sec); }
}
#==============================================================================
sub clock_to_seconds
# converts clock time (D*-HH:MM:SS) to seconds
{
  my($clock) = @_;
# days-hours:minutes:seconds
  if ($clock=~/(\d+)-(\d+):(\d+):(\d+)/) {
    return ($1*86400)+($2*3600)+($3*60)+$4;
  }
# days-hours:minutes
  elsif ($clock=~/(\d+)-(\d+):(\d+)/) {
    return ($1*86400)+($2*3600)+($3*60);
  }
# days-hours
  elsif ($clock=~/(\d+)-(\d+)/) {
    return ($1*86400)+($2*3600);
  }
# hours:minutes:seconds
  elsif ($clock=~/(\d+):(\d+):(\d+)/) {
    return ($1*3600)+($2*60)+$3;
  }
# minutes:seconds
  elsif ($clock=~/(\d+):(\d+)/) {
    return ($1*60)+$2;
  }
# minutes
  elsif ($clock=~/(\d+)/) {
    return ($1*60);
  }
}
#==============================================================================
sub catch_sig
# If a signal is thrown during the process, attempt to be neat
{
  if ($PAR->{jobid}) {
    warn("WARNING: swarm ended after job was submitted, canceling job $PAR->{jobid}\n");
    system("scancel $PAR->{jobid}");
  }
  else {
    dieWithError("swarm ended before job was submitted");
  }
}
#==============================================================================
sub append_to_tempdir_index
{
  my $p = 1;
  $p = 2 if ($OPT{p} == 2);
  my $fileContents = time().",$PAR->{user},$PAR->{tempname},$PAR->{subjobs},$p\n";
  appendToFile($PAR->{tempdir_index},$fileContents);
  chmod 0666, $PAR->{tempdir_index};
}
#==============================================================================
